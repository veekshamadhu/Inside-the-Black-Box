{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf91a623",
   "metadata": {},
   "source": [
    "### The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d164f",
   "metadata": {},
   "source": [
    "The data source for this XGBoost model is the UCI ML Repository: https://archive.ics.uci.edu/dataset/551/gas+turbine+co+and+nox+emission+data+set <br>\n",
    "This project uses the Gas Turbine CO and NOₓ Emission Dataset from the UCI Machine Learning Repository. It contains 36,733 hourly records collected from a gas turbine power plant in Turkey between 2011 and 2015. The dataset includes a mix of ambient and operational variables and can be used to predict carbon monoxide (CO) or nitrogen oxides (NOₓ) emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0e8a4",
   "metadata": {},
   "source": [
    "#### Metadata:\n",
    "AT - Ambient Temperature (°C)<br>\n",
    "AP - Ambient Pressure (mbar)<br>\n",
    "AH - Ambient Humidity (%)<br>\n",
    "AFDP = Air Filter Differential Pressure (mbar)<br>\n",
    "GHEP - Gas Turbine Exhaust Pressure (mbar)<br>\n",
    "TIT - Turbine Inlet Temperature (°C)<br>\n",
    "TAT- Turbine After Temperature (°C)<br>\n",
    "TEY - Turbine Energy Yield (MWh)<br>\n",
    "CDP - Compressor Discharge Pressure (mbar)<br>\n",
    "CO - Carbon monoxide emissions (mg/m³)<br>\n",
    "NO - Nitric Oxide emissions (mg/m³)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4d40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/veeksha_work/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/veeksha_work/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries for loading the data, feature engineering, and visualizations.\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np   \n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c94555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv files\n",
    "gt11 = pd.read_csv('gt_2011.csv')\n",
    "gt12 = pd.read_csv('gt_2012.csv')\n",
    "gt13 = pd.read_csv('gt_2013.csv')\n",
    "gt14 = pd.read_csv('gt_2014.csv')\n",
    "gt15 = pd.read_csv('gt_2015.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9f522b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7411, 11)\n",
      "(7628, 11)\n",
      "(7152, 11)\n",
      "(7158, 11)\n",
      "(7384, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.95320</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>84.985</td>\n",
       "      <td>2.5304</td>\n",
       "      <td>20.116</td>\n",
       "      <td>1048.7</td>\n",
       "      <td>544.92</td>\n",
       "      <td>116.27</td>\n",
       "      <td>10.799</td>\n",
       "      <td>7.4491</td>\n",
       "      <td>113.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.21910</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>87.523</td>\n",
       "      <td>2.3937</td>\n",
       "      <td>18.584</td>\n",
       "      <td>1045.5</td>\n",
       "      <td>548.50</td>\n",
       "      <td>109.18</td>\n",
       "      <td>10.347</td>\n",
       "      <td>6.4684</td>\n",
       "      <td>112.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.94915</td>\n",
       "      <td>1022.2</td>\n",
       "      <td>78.335</td>\n",
       "      <td>2.7789</td>\n",
       "      <td>22.264</td>\n",
       "      <td>1068.8</td>\n",
       "      <td>549.95</td>\n",
       "      <td>125.88</td>\n",
       "      <td>11.256</td>\n",
       "      <td>3.6335</td>\n",
       "      <td>88.147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  1.95320  1020.1  84.985  2.5304  20.116  1048.7  544.92  116.27  10.799   \n",
       "1  1.21910  1020.1  87.523  2.3937  18.584  1045.5  548.50  109.18  10.347   \n",
       "2  0.94915  1022.2  78.335  2.7789  22.264  1068.8  549.95  125.88  11.256   \n",
       "\n",
       "       CO      NOX  \n",
       "0  7.4491  113.250  \n",
       "1  6.4684  112.020  \n",
       "2  3.6335   88.147  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many rows and columns are in the datasets?\n",
    "print(gt11.shape)\n",
    "print(gt12.shape)\n",
    "print(gt13.shape)\n",
    "print(gt14.shape)\n",
    "print(gt15.shape)\n",
    "\n",
    "#show dataframe\n",
    "gt15.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2267c182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36733, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframes of all years\n",
    "gt_combined = pd.concat([gt11, gt12, gt13, gt14, gt15], axis=0, ignore_index=True)\n",
    "gt_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633344c",
   "metadata": {},
   "source": [
    "### Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5c1229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "TEY     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "gt_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6ed1381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT: float64\n",
      "AP: float64\n",
      "AH: float64\n",
      "AFDP: float64\n",
      "GTEP: float64\n",
      "TIT: float64\n",
      "TAT: float64\n",
      "TEY: float64\n",
      "CDP: float64\n",
      "CO: float64\n",
      "NOX: float64\n"
     ]
    }
   ],
   "source": [
    "# Understanding the data types of the features\n",
    "for col in gt_combined.columns:\n",
    "    print(f\"{col}: {gt_combined[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4fc1b6",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621ed66",
   "metadata": {},
   "source": [
    "### Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0dd8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Define independent (X) and dependent (y) variables\n",
    "X = gt_combined.drop('NOX', axis=1)\n",
    "y = gt_combined['NOX']\n",
    "X_np = X.values\n",
    "y_np = y.values\n",
    "\n",
    "# Split into Training and Testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af29c0",
   "metadata": {},
   "source": [
    "#### Manually coded XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca201a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute gradients and Hessians (second-order)\n",
    "def compute_grad_hess(y_true, y_pred):\n",
    "    grad = y_pred - y_true\n",
    "    hess = np.ones_like(y_true)\n",
    "    return grad, hess\n",
    "\n",
    "# Calculate gain from a split with regularization\n",
    "def calc_split_gain(Gl, Hl, Gr, Hr, reg_lambda, gamma):\n",
    "    left = Gl ** 2 / (Hl + reg_lambda)\n",
    "    right = Gr ** 2 / (Hr + reg_lambda)\n",
    "    parent = (Gl + Gr) ** 2 / (Hl + Hr + reg_lambda)\n",
    "    gain = 0.5 * (left + right - parent) - gamma\n",
    "    return gain\n",
    "\n",
    "# Find best split considering gradients, Hessians & regularization\n",
    "def best_split(X_col, grad, hess, reg_lambda, gamma, min_child_weight):\n",
    "    sort_idx = np.argsort(X_col)\n",
    "    X_sorted = X_col[sort_idx]\n",
    "    grad_sorted = grad[sort_idx]\n",
    "    hess_sorted = hess[sort_idx]\n",
    "    unique_vals = np.unique(X_sorted)\n",
    "    if len(unique_vals) == 1:\n",
    "        return None, -np.inf\n",
    "    thresholds = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
    "    best_gain, best_thresh = -np.inf, None\n",
    "    for thr in thresholds:\n",
    "        left_mask = X_sorted <= thr\n",
    "        right_mask = ~left_mask\n",
    "        Gl = grad_sorted[left_mask].sum()\n",
    "        Hl = hess_sorted[left_mask].sum()\n",
    "        Gr = grad_sorted[right_mask].sum()\n",
    "        Hr = hess_sorted[right_mask].sum()\n",
    "        if Hl < min_child_weight or Hr < min_child_weight:\n",
    "            continue\n",
    "        gain = calc_split_gain(Gl, Hl, Gr, Hr, reg_lambda, gamma)\n",
    "        if gain > best_gain:\n",
    "            best_gain, best_thresh = gain, thr\n",
    "    return best_thresh, best_gain\n",
    "\n",
    "# Fit a tree with second-order info and regularization\n",
    "def fit_tree_xgb(X, grad, hess, depth, reg_lambda, gamma, min_child_weight):\n",
    "    if depth == 0 or np.sum(hess) < 2 * min_child_weight:\n",
    "        G, H = grad.sum(), hess.sum()\n",
    "        value = -G / (H + reg_lambda)\n",
    "        return {'leaf': True, 'value': value}\n",
    "    n_samples, n_features = X.shape\n",
    "    best_feat, best_thr, best_gain = None, None, -np.inf\n",
    "    for f in range(n_features):\n",
    "        thr, gain = best_split(X[:, f], grad, hess, reg_lambda, gamma, min_child_weight)\n",
    "        if thr is not None and gain > best_gain:\n",
    "            best_feat, best_thr, best_gain = f, thr, gain\n",
    "    if best_feat is None:\n",
    "        G, H = grad.sum(), hess.sum()\n",
    "        value = -G / (H + reg_lambda)\n",
    "        return {'leaf': True, 'value': value}\n",
    "    left_mask = X[:, best_feat] <= best_thr\n",
    "    right_mask = ~left_mask\n",
    "    left_tree = fit_tree_xgb(X[left_mask], grad[left_mask], hess[left_mask], depth - 1,\n",
    "                            reg_lambda, gamma, min_child_weight)\n",
    "    right_tree = fit_tree_xgb(X[right_mask], grad[right_mask], hess[right_mask], depth - 1,\n",
    "                             reg_lambda, gamma, min_child_weight)\n",
    "    return {'leaf': False, 'feature': best_feat, 'threshold': best_thr,\n",
    "            'left': left_tree, 'right': right_tree}\n",
    "\n",
    "# Predict with the XGBoost tree (same as before)\n",
    "def predict_tree_xgb(tree, X):\n",
    "    preds = np.zeros(X.shape[0])\n",
    "    for i, x in enumerate(X):\n",
    "        node = tree\n",
    "        while not node['leaf']:\n",
    "            if x[node['feature']] <= node['threshold']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        preds[i] = node['value']\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97e5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build XGBoost model incrementally with second-order info and regularization\n",
    "def build_xgboost(X, y, n_estimators=50, learning_rate=0.1,\n",
    "                  max_depth=3, reg_lambda=1.0, gamma=0.0, min_child_weight=1):\n",
    "    X, y = np.asarray(X), np.asarray(y)\n",
    "    y_pred = np.full(len(y), y.mean())\n",
    "    trees = []\n",
    "    for _ in range(n_estimators):\n",
    "        grad, hess = compute_grad_hess(y, y_pred)\n",
    "        tree = fit_tree_xgb(X, grad, hess, max_depth, reg_lambda, gamma, min_child_weight)\n",
    "        update = predict_tree_xgb(tree, X)\n",
    "        y_pred += learning_rate * update\n",
    "        trees.append(tree)\n",
    "    return {'init_value': y.mean(), 'trees': trees, 'learning_rate': learning_rate}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc10838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model = build_xgboost(X_train, y_train, n_estimators=100, learning_rate=0.1,\n",
    "                      max_depth=3, reg_lambda=1.0, gamma=0.1, min_child_weight=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f6018",
   "metadata": {},
   "source": [
    "####  XGBoost regressor built using xgboost library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af663dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model\n",
    "xgb = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42)\n",
    "\n",
    "# Step 4: Train the Model\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84d4fb",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2884db",
   "metadata": {},
   "source": [
    "####  Manually coded XGBoost regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7840e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with manual XGBoost model\n",
    "def predict_xgboost(X, model):\n",
    "    X = np.asarray(X)\n",
    "    y_pred = np.full(X.shape[0], model['init_value'])\n",
    "    for tree in model['trees']:\n",
    "        y_pred += model['learning_rate'] * predict_tree_xgb(tree, X)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95b10d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_manual = predict_xgboost(X_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23808745",
   "metadata": {},
   "source": [
    "#### xgboost library built XGBoost regression predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43dc845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Predict with library XGBoost model\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393db92c",
   "metadata": {},
   "source": [
    "### Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81e3de",
   "metadata": {},
   "source": [
    "#### Evaluating manual xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c49d38d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.19\n",
      "MSE: 34.27\n",
      "RMSE: 5.85\n",
      "R² Score: 0.7414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred_manual)\n",
    "mse = mean_squared_error(y_test, y_pred_manual)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_manual)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118284dc",
   "metadata": {},
   "source": [
    "#### Evaluating xgboost library model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a79a6428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.43\n",
      "MSE: 12.89\n",
      "RMSE: 3.59\n",
      "R² Score: 0.9027\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d774160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.91\n",
      "65.29306726921297\n",
      "25.905\n"
     ]
    }
   ],
   "source": [
    "# Printing CLV data stats for model eval metric comparison\n",
    "print(y.max())\n",
    "print(y.mean())\n",
    "print(y.min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
